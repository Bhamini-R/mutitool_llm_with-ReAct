{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb2c5e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello bhams\n"
     ]
    }
   ],
   "source": [
    "print(\"hello bhams\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "071a9cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "print(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ea51992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (2.5.3)\n",
      "Collecting langchain (from -r requirements.txt (line 2))\n",
      "  Using cached langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langgraph (from -r requirements.txt (line 3))\n",
      "  Using cached langgraph-0.4.5-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting langchain-core (from -r requirements.txt (line 4))\n",
      "  Using cached langchain_core-0.3.60-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-community (from -r requirements.txt (line 5))\n",
      "  Using cached langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (0.21.0)\n",
      "Collecting langchain-groq (from -r requirements.txt (line 7))\n",
      "  Using cached langchain_groq-0.3.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting arxiv (from -r requirements.txt (line 8))\n",
      "  Using cached arxiv-2.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting wikipedia (from -r requirements.txt (line 9))\n",
      "  Using cached wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from pydantic->-r requirements.txt (line 1)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from pydantic->-r requirements.txt (line 1)) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from pydantic->-r requirements.txt (line 1)) (4.11.0)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain->-r requirements.txt (line 2))\n",
      "  Using cached langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain->-r requirements.txt (line 2))\n",
      "  Using cached langsmith-0.3.42-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic (from -r requirements.txt (line 1))\n",
      "  Using cached pydantic-2.11.4-py3-none-any.whl.metadata (66 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (2.0.30)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (2.32.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (6.0.1)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic->-r requirements.txt (line 1))\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-extensions!=4.7.0,>=4.6.0 (from pydantic-core==2.14.6->pydantic->-r requirements.txt (line 1))\n",
      "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic->-r requirements.txt (line 1))\n",
      "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.26 (from langgraph->-r requirements.txt (line 3))\n",
      "  Using cached langgraph_checkpoint-2.0.26-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-prebuilt>=0.1.8 (from langgraph->-r requirements.txt (line 3))\n",
      "  Using cached langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk>=0.1.42 (from langgraph->-r requirements.txt (line 3))\n",
      "  Using cached langgraph_sdk-0.1.69-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting xxhash<4.0.0,>=3.5.0 (from langgraph->-r requirements.txt (line 3))\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from langchain-core->-r requirements.txt (line 4)) (8.2.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from langchain-core->-r requirements.txt (line 4)) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from langchain-core->-r requirements.txt (line 4)) (23.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from langchain-community->-r requirements.txt (line 5)) (3.9.5)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community->-r requirements.txt (line 5))\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community->-r requirements.txt (line 5))\n",
      "  Using cached pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community->-r requirements.txt (line 5))\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from langchain-community->-r requirements.txt (line 5)) (1.26.4)\n",
      "Collecting groq<1,>=0.4.1 (from langchain-groq->-r requirements.txt (line 7))\n",
      "  Using cached groq-0.25.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting feedparser~=6.0.10 (from arxiv->-r requirements.txt (line 8))\n",
      "  Using cached feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from wikipedia->-r requirements.txt (line 9)) (4.12.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 5)) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 5)) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 5)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 5)) (1.9.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 5))\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 5))\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv->-r requirements.txt (line 8))\n",
      "  Using cached sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq->-r requirements.txt (line 7)) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq->-r requirements.txt (line 7)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq->-r requirements.txt (line 7)) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq->-r requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core->-r requirements.txt (line 4)) (2.1)\n",
      "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.26->langgraph->-r requirements.txt (line 3))\n",
      "  Downloading ormsgpack-1.9.1-cp312-cp312-win_amd64.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/44.4 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 41.0/44.4 kB 2.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- 44.4/44.4 kB 550.3 kB/s eta 0:00:00\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk>=0.1.42->langgraph->-r requirements.txt (line 3))\n",
      "  Downloading orjson-3.10.18-cp312-cp312-win_amd64.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.0/43.0 kB ? eta 0:00:00\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 2)) (1.0.0)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 2))\n",
      "  Downloading zstandard-0.23.0-cp312-cp312-win_amd64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 2)) (3.0.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from beautifulsoup4->wikipedia->-r requirements.txt (line 9)) (2.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq->-r requirements.txt (line 7)) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq->-r requirements.txt (line 7)) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\m3bha\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 5)) (1.0.0)\n",
      "Using cached langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
      "Using cached pydantic-2.11.4-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/2.0 MB 2.0 MB/s eta 0:00:01\n",
      "   - -------------------------------------- 0.1/2.0 MB 2.0 MB/s eta 0:00:01\n",
      "   - -------------------------------------- 0.1/2.0 MB 2.0 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.2/2.0 MB 1.2 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/2.0 MB 1.2 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/2.0 MB 1.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.4/2.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.4/2.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.6/2.0 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.6/2.0 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 0.9/2.0 MB 1.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.1/2.0 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.2/2.0 MB 2.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.3/2.0 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.5/2.0 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.5/2.0 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.5/2.0 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.5/2.0 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.5/2.0 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.5/2.0 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.6/2.0 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.7/2.0 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.9/2.0 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.0/2.0 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 1.7 MB/s eta 0:00:00\n",
      "Using cached langgraph-0.4.5-py3-none-any.whl (155 kB)\n",
      "Using cached langchain_core-0.3.60-py3-none-any.whl (437 kB)\n",
      "Using cached langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
      "Using cached langchain_groq-0.3.2-py3-none-any.whl (15 kB)\n",
      "Using cached arxiv-2.2.0-py3-none-any.whl (11 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "Using cached groq-0.25.0-py3-none-any.whl (129 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Using cached langgraph_checkpoint-2.0.26-py3-none-any.whl (44 kB)\n",
      "Using cached langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n",
      "Using cached langgraph_sdk-0.1.69-py3-none-any.whl (48 kB)\n",
      "Using cached langsmith-0.3.42-py3-none-any.whl (360 kB)\n",
      "Using cached pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading orjson-3.10.18-cp312-cp312-win_amd64.whl (134 kB)\n",
      "   ---------------------------------------- 0.0/134.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 134.8/134.8 kB 7.8 MB/s eta 0:00:00\n",
      "Downloading ormsgpack-1.9.1-cp312-cp312-win_amd64.whl (125 kB)\n",
      "   ---------------------------------------- 0.0/125.4 kB ? eta -:--:--\n",
      "   ---------------------------------------  122.9/125.4 kB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 125.4/125.4 kB 2.4 MB/s eta 0:00:00\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading zstandard-0.23.0-cp312-cp312-win_amd64.whl (495 kB)\n",
      "   ---------------------------------------- 0.0/495.6 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 122.9/495.6 kB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 358.4/495.6 kB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  491.5/495.6 kB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  491.5/495.6 kB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 495.6/495.6 kB 2.8 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: wikipedia, sgmllib3k\n",
      "  Building wheel for wikipedia (setup.py): started\n",
      "  Building wheel for wikipedia (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11706 sha256=b89557a2c449eb2c32da8938866a0e470fa0a8cd1c5171caa56907966fee9f0e\n",
      "  Stored in directory: c:\\users\\m3bha\\appdata\\local\\pip\\cache\\wheels\\63\\47\\7c\\a9688349aa74d228ce0a9023229c6c0ac52ca2a40fe87679b8\n",
      "  Building wheel for sgmllib3k (setup.py): started\n",
      "  Building wheel for sgmllib3k (setup.py): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6060 sha256=36e625da7e5969957c6c72db9c0a070d42e5e2f7af3d24fc5e07279914f920a5\n",
      "  Stored in directory: c:\\users\\m3bha\\appdata\\local\\pip\\cache\\wheels\\03\\f5\\1a\\23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
      "Successfully built wikipedia sgmllib3k\n",
      "Installing collected packages: sgmllib3k, zstandard, xxhash, typing-extensions, ormsgpack, orjson, marshmallow, httpx-sse, feedparser, wikipedia, typing-inspection, typing-inspect, pydantic-core, arxiv, pydantic, langgraph-sdk, dataclasses-json, pydantic-settings, langsmith, groq, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain-groq, langgraph-prebuilt, langchain, langgraph, langchain-community\n",
      "  Attempting uninstall: zstandard\n",
      "    Found existing installation: zstandard 0.22.0\n",
      "    Uninstalling zstandard-0.22.0:\n",
      "      Successfully uninstalled zstandard-0.22.0\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.14.6\n",
      "    Uninstalling pydantic_core-2.14.6:\n",
      "      Successfully uninstalled pydantic_core-2.14.6\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.5.3\n",
      "    Uninstalling pydantic-2.5.3:\n",
      "      Successfully uninstalled pydantic-2.5.3\n",
      "Successfully installed arxiv-2.2.0 dataclasses-json-0.6.7 feedparser-6.0.11 groq-0.25.0 httpx-sse-0.4.0 langchain-0.3.25 langchain-community-0.3.24 langchain-core-0.3.60 langchain-groq-0.3.2 langchain-text-splitters-0.3.8 langgraph-0.4.5 langgraph-checkpoint-2.0.26 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.69 langsmith-0.3.42 marshmallow-3.26.1 orjson-3.10.18 ormsgpack-1.9.1 pydantic-2.11.4 pydantic-core-2.33.2 pydantic-settings-2.9.1 sgmllib3k-1.0.0 typing-extensions-4.13.2 typing-inspect-0.9.0 typing-inspection-0.4.0 wikipedia-1.4.0 xxhash-3.5.0 zstandard-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49543935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools  \n",
    "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
    "from langchain_community.tools.wikipedia.tool import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6efb57f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv\n"
     ]
    }
   ],
   "source": [
    "api_wrapper_arxiv = ArxivAPIWrapper(top_k_results=2,doc_content_chars_max=500)\n",
    "arxiv = ArxivQueryRun(api_wrapper=api_wrapper_arxiv, description=\"Query Arxiv papers\")     # making the tools required using the API wrappers\n",
    "print(arxiv.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6be2181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Published: 2025-05-15\\nTitle: Plasticity as the Mirror of Empowerment\\nAuthors: David Abel, Michael Bowling, André Barreto, Will Dabney, Shi Dong, Steven Hansen, Anna Harutyunyan, Khimya Khetarpal, Clare Lyle, Razvan Pascanu, Georgios Piliouras, Doina Precup, Jonathan Richens, Mark Rowland, Tom Schaul, Satinder Singh\\nSummary: Agents are minimally entities that are influenced by their past observations\\nand act to influence future observations. This latter capacity is captured by\\nempowerment, which '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv.invoke(\"Plasticity as the Mirror of Empowerment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fd8bfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia\n"
     ]
    }
   ],
   "source": [
    "api_wrapper_wiki = WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=500)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper_wiki, description=\"Query Wikipedia articles\")   # making the wiki tools using API too\n",
    "print(wiki.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "498eeff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Dyslexia\\nSummary: Dyslexia, previously known as word blindness, is a learning disability that affects either reading or writing. Different people are affected to different degrees. Problems may include difficulties in spelling words, reading quickly, writing words, \"sounding out\" words in the head, pronouncing words when reading aloud and understanding what one reads. Often these difficulties are first noticed at school. The difficulties are involuntary, and people with this disorder have '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.invoke(\"Dislexia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e4eeb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")   # Tavily is more like a search engine for answering questions.like google, using its API\n",
    "os.environ[\"GROQ_API_KEY\"] =os.getenv(\"GROQ_API_KEY\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f73ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tavily = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce699dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'DeepSeek (深度求索): Latest News and Updates',\n",
       "  'url': 'https://www.scmp.com/topics/deepseek',\n",
       "  'content': 'The latest speculation includes R2’s imminent launch and the new benchmarks that it set in terms of cost-efficiency and performance.\\n\\nAkeso shares slump despite second China approval for lung cancer drug\\n\\nChinese regulator grants second approval for lung cancer drug ivonescimab, which has outperformed Merck’s Keytruda in phase three trial.\\n\\nBaidu offers new AI models at lower cost than DeepSeek’s products [...] The technology is already ‘providing new ideas and approaches’ according to the lead designer at the Shenyang Aircraft Design Institute.\\n\\nDeepSeek’s new maths-solving model is generating buzz, but mostly about R2\\n\\nThe Prover-V2 release has captured attention online, with many on social media wondering what it means for the start-up’s next reasoning model.\\n\\nAlibaba’s Qwen3 AI model family helps narrow US-China tech gap: analysts [...] Chinese customers have been notified by Nvidia that it aims to release the downgraded version of the H20 chip in July, sources say.\\n\\nDeepSeek’s AI system gets faster with Tencent’s open-source boost\\n\\nThe leading Chinese AI start-up has adopted an open-source technical solution from Tencent, leading to a ‘huge speed boost’.\\n\\nAlibaba’s Qwen3 unseats DeepSeek’s R1 as world’s top-ranked open-source AI model',\n",
       "  'score': 0.8190992},\n",
       " {'title': \"China's DeepSeek Launches New AI Model—Here's What To Know\",\n",
       "  'url': 'https://www.forbes.com/sites/tylerroush/2025/03/25/deepseek-launches-ai-model-upgrade-amid-openai-rivalry-heres-what-to-know/',\n",
       "  'content': \"The latest update included “significant improvements” across several benchmark tests for the language model, DeepSeek said, in addition to upgrades to front-end web development, Chinese writing proficiency—with new features like “interactive rewriting,” according to the company—and Chinese search capabilities like “enhanced report analysis.” [...] The Chinese AI company said its latest model demonstrated “significant improvements” in benchmark ... More performance.\\n\\nKey Facts\\n\\nDeepSeek launched an upgrade to its V3 large language model, DeepSeek-V3-0324, on the AI development platform Hugging Face on Tuesday, which the startup marketed as including improvements in reasoning and coding capabilities over its earlier V3 model. [...] Get Forbes Breaking News Text Alerts: We’re launching text message alerts so you'll always know the biggest stories shaping the day’s headlines. Text “Alerts” to (201) 335-0739 or sign up here.\\n\\nWhat To Watch For\\n\\nWhether the latest DeepSeek model impacts U.S. tech stocks. Shares for Nvidia dropped by 1.2% as of 9:35 a.m. EDT, while other stocks like Broadcom (0.6%) and Tesla (0.3%) declined slightly. Apple (0.3%), Meta (0.7%) and Microsoft (0.3%) were up Tuesday morning.\\n\\nWhat Is Deepseek?\",\n",
       "  'score': 0.8127637},\n",
       " {'title': \"DeepSeek News | Today's Latest Stories - Reuters\",\n",
       "  'url': 'https://www.reuters.com/technology/deepseek/',\n",
       "  'content': \"Chinese tech giant Tencent on Thursday released a new AI model that it says can answer queries faster than global hit DeepSeek's R1, in the latest sign the\",\n",
       "  'score': 0.8047902},\n",
       " {'title': 'Moolenaar, Krishnamoorthi Unveil Explosive Report on Chinese AI ...',\n",
       "  'url': 'http://selectcommitteeontheccp.house.gov/media/press-releases/moolenaar-krishnamoorthi-unveil-explosive-report-chinese-ai-firm-deepseek',\n",
       "  'content': 'Titled, “DeepSeek Unmasked: Exposing the CCP’s Latest Tool For Spying, Stealing, and Subverting U.S. Export Control Restrictions,” the bipartisan report reveals that DeepSeek covertly funnels American user data to the Chinese Communist Party, manipulates information to align with CCP propaganda, and was trained using\\xa0material unlawfully obtained from\\xa0U.S. AI models. The report also\\xa0highlights reporting\\xa0that DeepSeek operates on tens of thousands of Nvidia chips—some of which are subject to U.S. [...] Moolenaar, Krishnamoorthi Unveil Explosive Report on Chinese AI Firm DeepSeek — Demand Answers from Nvidia Over Chip Use\\n\\nWASHINGTON, D.C. – Today, Chairman John Moolenaar (R-MI) and Ranking Member Raja Krishnamoorthi (D-IL) of the House Select Committee on China released a new investigative report exposing DeepSeek, a Chinese artificial intelligence platform, as a serious national security threat to the United States.',\n",
       "  'score': 0.7323053},\n",
       " {'title': 'How Deepseek is Changing the AI Landscape',\n",
       "  'url': 'https://news.gsu.edu/2025/02/04/how-deepseek-is-changing-the-a-i-landscape/',\n",
       "  'content': 'On Monday January 27, a little known Chinese start-up called Deepseek sent shockwaves and panic through Silicon Valley and the global stock market with the launch of their generative artificial intelligence(AI) model that rivals the models of tech giants like OpenAI, Meta and Google. It’s AI assistant became the no. 1 downloaded app in the U.S., surprising an industry that assumed only big Western companies could dominate AI. Many AI-related stocks, including Nvidia, took a hit as investors [...] Filed Under: Academic Unit News\\n\\nPrimary Sidebar\\n\\nRecent Stories\\n\\nNew Study Reveals Generative AI Boosts Job Growth and Productivity\\n\\nTen Graduate Students Present at Prestigious Analytics Conference\\n\\nCongratulations, Robinson College Class of Spring 2025!\\n\\nUndergrad Finance Students Have $1.4 Million on the Line\\n\\nMaster’s in Information Systems Alumnus Builds AI-Powered Tools for ADP\\n\\nRobinson College of Business\\nNews Hub\\n\\nSend this to a friend [...] Main navigation\\n\\nGeorgia State News Hub\\n\\nMain navigation\\n\\nHow Deepseek is Changing the AI Landscape\\n\\nHow Deepseek is Changing the AI Landscape\\n\\nFebruary 4, 2025\\n\\nMedia Contact\\n\\nHolly Frew\\n\\nOffice of Communications & MarketingRobinson College of Business\\n\\n[email\\xa0protected]',\n",
       "  'score': 0.7040996}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily.invoke(\"what is the latest news about deepseek?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5156040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all these tools in the list\n",
    "tools = [arxiv, wiki, tavily]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfa5f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM model\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(                                     #LLM model used here is groq's ChatGroq qwen-qwq-32b \n",
    "    model=\"qwen-qwq-32b\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65e2a116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n<think>\\nOkay, so the user is asking, \"What is LLM?\" Alright, let me start by recalling what I know. LLM stands for Large Language Model. But wait, maybe I should double-check that. Hmm, yes, I think that\\'s right. So, first, I need to explain what a language model is. A language model is a type of AI that\\'s designed to understand and generate human language. But specifically, LLMs are the big ones, right? They have a lot of parameters. Parameters in machine learning terms are the variables the model learns from the data. So, LLMs have millions or billions of them.\\n\\nNow, why are they called \"large\"? Probably because of the vast amount of data they\\'re trained on. They use huge datasets from the internet, books, articles, etc. That\\'s how they learn to generate coherent text. Examples of LLMs include models like GPT, BERT, and others from companies like OpenAI, Google, and Meta. Wait, but the user might not know those names, so maybe I should mention a few examples but not get too technical.\\n\\nI should also mention their capabilities. They can do things like writing stories, composing emails, coding, and even understanding context. But I should note that they have limitations too. Like, they might not always be accurate or have up-to-date information. Also, there are ethical concerns, such as generating biased content or misinformation. Oh, right, and their training data is usually up to a certain cutoff date, so they can\\'t know things that happened after that.\\n\\nThe user might be asking because they\\'ve heard the term but aren\\'t familiar with the specifics. Maybe they\\'re a student or someone just starting to learn about AI. So, I should explain in simple terms without too much jargon. Let me structure it step by step. Start with the acronym, then define what a language model is, explain the \"large\" part, mention examples, applications, and then the limitations and ethical issues. That should cover the basics without overwhelming them.\\n\\nWait, also, maybe explain a bit about how they work. Like, they predict the next word in a sentence based on prior words. But maybe that\\'s too technical. Hmm. Maybe keep it high-level. But to ensure clarity, perhaps a brief mention of how they process input and generate output. \\n\\nAlso, mention that they are machine learning models, specifically neural networks. But again, maybe keep it simple. Let me see. The user could be looking for a straightforward definition, so I should prioritize that first, then add context. Let\\'s outline the structure:\\n\\n1. Definition of LLM (Large Language Model)\\n2. Explanation of what a language model does\\n3. What makes them \"large\" (parameters, data size)\\n4. Examples (GPT, BERT, etc.)\\n5. Applications (writing, coding, customer service, etc.)\\n6. Limitations (accuracy, bias, data cutoff)\\n7. Ethical considerations (misuse, misinformation)\\n\\nThat seems comprehensive. Let me make sure not to miss any key points. Also, maybe mention that they are trained on a diverse range of internet text, which helps them understand various topics. But also, that diversity can lead to varied quality and potential biases from the training data.\\n\\nAnother point: LLMs can be fine-tuned for specific tasks, so they\\'re versatile. Like, GPT can write stories, but with fine-tuning, it can also be used for customer support chatbots. \\n\\nWait, maybe the user is a developer thinking about using an LLM, so mentioning applications could be useful. But since the question is \"what is LLM?\", the focus should be on the definition, components, and basic understanding.\\n\\nI should also clarify that LLMs are not just for generating text; they can answer questions, translate languages, perform logical reasoning, and even create art or music in some cases. Although maybe that\\'s stretching it—some models do that, but the primary function is text-based.\\n\\nAlso, touch on the fact that they require significant computational resources both to train and deploy. That\\'s why they\\'re typically developed by large companies with the necessary infrastructure.\\n\\nAlright, putting it all together in a clear, concise answer. Avoid acronyms unless explained. Make sure each part flows logically. Start with the definition, then break down each component. Use examples to make it concrete. Address both the positives and the caveats. That should cover the user\\'s question effectively.\\n</think>\\n\\n**LLM stands for Large Language Model**, which is a type of artificial intelligence (AI) system designed to understand and generate human-like text. Here\\'s a breakdown of what LLMs are and their key features:\\n\\n---\\n\\n### 1. **What is a Language Model?**\\n   - A **language model** is an AI algorithm trained to predict and generate text based on patterns learned from large datasets. It can:\\n     - Compose sentences, paragraphs, or entire documents.\\n     - Answer questions, write stories, code, or even perform logical reasoning.\\n     - Understand context and infer meaning from input text.\\n\\n---\\n\\n### 2. **Why \"Large\"?**\\n   - **Size**: LLMs are distinguished by their **scale**:\\n     - **Parameters**: They have billions of parameters (variables the model adjusts during training), making them highly capable but requiring significant computational power.\\n     - **Training Data**: Trained on massive datasets (e.g., books, websites, articles, and code) to learn diverse topics and language styles.\\n   - **Capabilities**: Their large size allows them to perform complex tasks with greater accuracy and creativity than smaller models.\\n\\n---\\n\\n### 3. **Examples of LLMs**\\n   - **GPT (Generative Pre-trained Transformer)** by OpenAI (e.g., GPT-3, GPT-4).\\n   - **BERT** by Google (primarily for understanding context).\\n   - **Turing-NLG, PaLM** (Google), **Llama** (Meta), and **BLOOM** (open-source).\\n\\n---\\n\\n### 4. **Key Applications**\\n   - **Content Creation**: Writing articles, stories, or social media posts.\\n   - **Customer Service**: Powering chatbots for automated support.\\n   - **Programming**: Assisting with coding (e.g., GitHub Copilot).\\n   - **Research**: Summarizing papers or generating hypotheses.\\n   - **Education**: Personalized learning tools or language tutoring.\\n\\n---\\n\\n### 5. **How Do They Work?**\\n   - **Training**: LLMs are trained on unstructured text data to learn grammar, semantics, and context.\\n   - **Generation**: When given a prompt (e.g., a question or topic), they predict the most likely next words, creating coherent outputs.\\n   - **Fine-Tuning**: Many LLMs are \"fine-tuned\" for specific tasks (e.g., medical or legal text).\\n\\n---\\n\\n### 6. **Limitations & Challenges**\\n   - **Accuracy**: Can occasionally produce errors, hallucinations (made-up information), or biased outputs based on training data.\\n   - **Data Bias**: Reflects biases present in their training data (e.g., stereotypes or outdated views).\\n   - **Ethical Concerns**: Risks include spreading misinformation, enabling harmful content, or privacy issues.\\n   - **Cutoff Date**: LLMs’ knowledge is limited to their training data, which typically stops at a certain point (e.g., early 2023 for some models).\\n\\n---\\n\\n### 7. **Why Are LLMs Important?**\\n   - **Versatility**: They can adapt to diverse tasks without needing task-specific training.\\n   - **Advances in AI**: Represent a leap in natural language processing (NLP) and generative AI.\\n   - **Accessibility**: Companies like OpenAI and Meta offer APIs for developers to integrate LLMs into apps.\\n\\n---\\n\\n### 8. **Ethical and Societal Impact**\\n   - **Pros**: Boosts productivity, aids in creative writing, and democratizes access to AI tools.\\n   - **Cons**: Risks include misuse for deepfakes, automated spam, or reinforcement of societal biases.\\n\\n---\\n\\n### **In Summary**\\nLLMs are powerful AI systems capable of generating and understanding human language at scale. While they revolutionize fields like content creation and customer service, their use requires careful oversight to mitigate ethical risks. Think of them as advanced \"text processors\" that learn from massive data to mimic human-like communication.\\n\\nIf you\\'re interested in specific LLMs or use cases, let me know!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1759, 'prompt_tokens': 15, 'total_tokens': 1774, 'completion_time': 4.295573354, 'prompt_time': 0.002888774, 'queue_time': 0.241063445, 'total_time': 4.298462128}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_512a3da6bb', 'finish_reason': 'stop', 'logprobs': None}, id='run--15d04511-a4c2-4419-ba09-ed7ac922cc43-0', usage_metadata={'input_tokens': 15, 'output_tokens': 1759, 'total_tokens': 1774})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is llm?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e785a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "218eefcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_764p', 'function': {'arguments': '{\"query\": \"recent news about DeepSeek\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 236, 'prompt_tokens': 324, 'total_tokens': 560, 'completion_time': 0.575348318, 'prompt_time': 0.020063468, 'queue_time': 0.248391862, 'total_time': 0.595411786}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_512a3da6bb', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--6adbed92-fcef-424f-bc54-b03b72ea119c-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'recent news about DeepSeek'}, 'id': 'call_764p', 'type': 'tool_call'}], usage_metadata={'input_tokens': 324, 'output_tokens': 236, 'total_tokens': 560})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "llm_with_tools.invoke(\"What is the recent news about deepseek?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b15cd2",
   "metadata": {},
   "source": [
    "#Similarly examples of calling arxiv and wikipedia tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c666683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_pac5', 'function': {'arguments': '{\"query\": \"agentic AI recent\"}', 'name': 'arxiv'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 249, 'prompt_tokens': 326, 'total_tokens': 575, 'completion_time': 0.604717227, 'prompt_time': 0.020289803, 'queue_time': 0.25291968600000003, 'total_time': 0.62500703}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_3796682456', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--950d0181-8022-4f29-a2df-e5a1541226eb-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'agentic AI recent'}, 'id': 'call_pac5', 'type': 'tool_call'}], usage_metadata={'input_tokens': 326, 'output_tokens': 249, 'total_tokens': 575})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"Give me a recent research paper on agentic ai?\")     ##arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d47a6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_6cwx', 'function': {'arguments': '{\"query\": \"Deep reinforcement learning\"}', 'name': 'wikipedia'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 496, 'prompt_tokens': 323, 'total_tokens': 819, 'completion_time': 1.226085092, 'prompt_time': 0.0223178, 'queue_time': 0.24610344, 'total_time': 1.248402892}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_512a3da6bb', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--6003d4d7-a69c-4bfd-a266-06d27881504f-0', tool_calls=[{'name': 'wikipedia', 'args': {'query': 'Deep reinforcement learning'}, 'id': 'call_6cwx', 'type': 'tool_call'}], usage_metadata={'input_tokens': 323, 'output_tokens': 496, 'total_tokens': 819})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"What is  deep Reinforcement Learning?\")     ##Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246a9c36",
   "metadata": {},
   "source": [
    "Also in some relevant cases, the LLM can directly give the response to the user's question, instead of calling a tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a9a22eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm here to help you with any information or tasks you need assistance with. How can I assist you today?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 133, 'prompt_tokens': 319, 'total_tokens': 452, 'completion_time': 0.33001489, 'prompt_time': 0.024801243, 'queue_time': 0.247279557, 'total_time': 0.354816133}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_3796682456', 'finish_reason': 'stop', 'logprobs': None}, id='run--30e3581d-600d-44f7-9bee-1c9f16a181bc-0', usage_metadata={'input_tokens': 319, 'output_tokens': 133, 'total_tokens': 452})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"how are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cbf1ac",
   "metadata": {},
   "source": [
    "WORKFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f391654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State schema\n",
    "from typing_extensions import TypedDict  \n",
    "from langchain_core.messages import AnyMessage #Human Message or AI Message\n",
    "from typing import Annotated  #labelling\n",
    "from langgraph.graph.message import add_messages  #Reducers in langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "428760be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc2eb2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entire Chatbot using LangGraph\n",
    "from IPython.display import display, Image\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de44b51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# node definition\n",
    "\n",
    "def tool_calling_llm(state:State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "#Build the graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "#Edges\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    #If the latest message (result) from assistant is a tool call -> tool condition routes to tools\n",
    "    #If the latest message (result) from assistant is not a tool call -> tools condition routes to tool_calling_llm\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "builder.add_edge(\"tools\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b224a561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "2505.10468\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  arxiv (call_xbfv)\n",
      " Call ID: call_xbfv\n",
      "  Args:\n",
      "    query: 2505.10468\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: arxiv\n",
      "\n",
      "Published: 2025-05-15\n",
      "Title: AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenge\n",
      "Authors: Ranjan Sapkota, Konstantinos I. Roumeliotis, Manoj Karkee\n",
      "Summary: This study critically distinguishes between AI Agents and Agentic AI,\n",
      "offering a structured conceptual taxonomy, application mapping, and challenge\n",
      "analysis to clarify their divergent design philosophies and capabilities. We\n",
      "begin by outlining the search strategy and foundational definitions,\n",
      "characterizing AI Agents \n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": \"2505.10468\"})     \n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "218cb9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# node definition\n",
    "\n",
    "def tool_calling_llm(state:State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "#Build the graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "#Edges\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    #If the latest message (result) from assistant is a tool call -> tool condition routes to tools\n",
    "    #If the latest message (result) from assistant is not a tool call -> tools condition routes to tool_calling_llm\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "builder.add_edge(\"tools\", \"tool_calling_llm\")\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2b3cf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the recent deepseek news and then please tell me the recent research paper on agentic ai?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_0b5j)\n",
      " Call ID: call_0b5j\n",
      "  Args:\n",
      "    query: Recent news about DeepSeek AI\n",
      "  arxiv (call_a739)\n",
      " Call ID: call_a739\n",
      "  Args:\n",
      "    query: agentic AI\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"DeepSeek News | Today's Latest Stories - Reuters\", \"url\": \"https://www.reuters.com/technology/deepseek/\", \"content\": \"Latest Stories ; January 30, 2025. Resource-poor Japan was girding for an AI energy surge. DeepSeek raised the stakes. ; January 30, 2025. Chinese state-linked\", \"score\": 0.8573986}, {\"title\": \"DeepSeek's Latest Breakthrough Is Redefining AI Race - CSIS\", \"url\": \"https://www.csis.org/analysis/deepseeks-latest-breakthrough-redefining-ai-race\", \"content\": \"Commentary\\n                     by                                                                                                                                                                                                                                                                                                                                                                                                   \\n\\nYasir Atalan\\n\\nPublished February 3, 2025 [...] From last month to this month, the real change is the efficiency. DeepSeek researchers found a way to get more computational power from NVIDIA chips, allowing foundational models to be trained with significantly less computational power. Smaller companies and startups will now be able to replicate low-cost algorithms and potentially innovate upon them, enabling the development of more affordable and accessible low-tier and specialized AI applications across various domains. [...] On January 20, contrary to what export controls promised, Chinese researchers at DeepSeek released a high-performance large language model (LLM)—R1—at a small fraction of OpenAI’s costs, showing how rapidly Beijing can innovate around U.S. hardware restrictions. This launch was not an isolated event. Ahead of the Lunar New Year, three other Chinese labs announced AI models they claimed could match—even surpass—OpenAI’s o1 performance on key benchmarks. These simultaneous releases, likely to be\", \"score\": 0.85624856}, {\"title\": \"DeepSeek SHOCKS the West AGAIN! Their New AI Model Is ...\", \"url\": \"https://www.youtube.com/watch?v=i_lGjqkvhiA\", \"content\": \"DeepSeek has released a powerful new open-source AI model called V3–0324, which rivals top Western models while running efficiently on local hardware like the Mac Studio. The model uses a mixture-of-experts architecture with 671 billion parameters, supports 128K context length, and is now fully available under the permissive MIT license. This major breakthrough in Chinese AI development is drawing global attention, fueling tech rivalry, and reshaping the landscape for startups, governments, and [...] DeepSeek SHOCKS the West AGAIN! Their New AI Model Is Smarter & Free (V3–0324) \\n AI Revolution \\n 1208 likes \\n 65989 views \\n 26 Mar 2025 \\n 👉🏻Register for 2-Day LIVE Training on AI for FREE: https://link.outskill.com/airevmm [...] 🔍 KEY TOPICS  \\nDeepSeek releases V3–0324, a powerful open-source AI model under the MIT license  \\nThe model uses a mixture-of-experts system with 671 billion parameters and runs on local hardware  \\nV3–0324 supports 128K context length and delivers fast, efficient performance even on a Mac Studio\", \"score\": 0.8409005}, {\"title\": \"How Deepseek is Changing the AI Landscape\", \"url\": \"https://news.gsu.edu/2025/02/04/how-deepseek-is-changing-the-a-i-landscape/\", \"content\": \"Filed Under: Academic Unit News\\n\\nPrimary Sidebar\\n\\nRecent Stories\\n\\nNew Study Reveals Generative AI Boosts Job Growth and Productivity\\n\\nTen Graduate Students Present at Prestigious Analytics Conference\\n\\nCongratulations, Robinson College Class of Spring 2025!\\n\\nUndergrad Finance Students Have $1.4 Million on the Line\\n\\nMaster’s in Information Systems Alumnus Builds AI-Powered Tools for ADP\\n\\nRobinson College of Business\\nNews Hub\\n\\nSend this to a friend [...] By making a powerful AI model open-source, DeepSeek has lowered the barrier to AI development, enabling more researchers, startups, and organizations to build and deploy AI without relying on big tech firms or government-backed research labs. It also challenges the idea that AI progress depends solely on massive computing power, proving that smarter software and hardware optimization can rival brute-force approaches. [...] Main navigation\\n\\nGeorgia State News Hub\\n\\nMain navigation\\n\\nHow Deepseek is Changing the AI Landscape\\n\\nHow Deepseek is Changing the AI Landscape\\n\\nFebruary 4, 2025\\n\\nMedia Contact\\n\\nHolly Frew\\n\\nOffice of Communications & MarketingRobinson College of Business\\n\\n[email protected]\", \"score\": 0.79484755}, {\"title\": \"DeepSeek shakes up AI sector – and other digital tech stories you ...\", \"url\": \"https://www.weforum.org/stories/2025/02/china-deepseek-shakes-up-ai-tech-stories/\", \"content\": \"A new open-source artificial intelligence (AI) model developed by Chinese start-up DeepSeek sent waves through the global tech community last month.\", \"score\": 0.767847}]\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: arxiv\n",
      "\n",
      "Published: 2025-02-25\n",
      "Title: Responsible AI Agents\n",
      "Authors: Deven R. Desai, Mark O. Riedl\n",
      "Summary: Thanks to advances in large language models, a new type of software agent,\n",
      "the artificial intelligence (AI) agent, has entered the marketplace. Companies\n",
      "such as OpenAI, Google, Microsoft, and Salesforce promise their AI Agents will\n",
      "go from generating passive text to executing tasks. Instead of a travel\n",
      "itinerary, an AI Agent would book all aspects of your trip. Instead of\n",
      "generating text or images\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here's the information based on the latest available data:\n",
      "\n",
      "**Recent DeepSeek News (as of March 2025):**\n",
      "- **Major Breakthrough**: DeepSeek released an open-source AI model (**V3-0324**) with 671 billion parameters, capable of running efficiently on local hardware like the Mac Studio. It supports 128K context length and uses a mixture-of-experts architecture.\n",
      "- **Competitive Edge**: Their model rivals top Western AI systems (e.g., OpenAI’s o1) at a fraction of the computational cost, bypassing U.S. hardware restrictions through software optimizations.\n",
      "- **Industry Impact**: This advancement lowers barriers for startups and researchers, enabling affordable, specialized AI applications. It has intensified global competition, particularly in China’s AI sector.\n",
      "- **Media Coverage**: Outlets like Reuters, CSIS, and the World Economic Forum highlight its role in reshaping the AI race and fostering innovation outside major tech giants.\n",
      "\n",
      "**Latest Research on Agentic AI (from Arxiv, Feb 25, 2025):**\n",
      "- **Paper**: *[Responsible AI Agents](https://arxiv.org/abs/...)* by Deven R. Desai and Mark O. Riedl.\n",
      "- **Focus**: Examines the shift from passive AI (e.g., text generation) to *active AI agents* that execute tasks (e.g., booking trips, managing workflows).\n",
      "- **Key Insight**: Emphasizes ethical and regulatory challenges, arguing that agentic AI requires frameworks to ensure accountability and prevent misuse.\n",
      "- **Significance**: Highlights the need for responsible design as AI moves toward autonomous decision-making.\n",
      "\n",
      "Let me know if you'd like deeper insights on either topic!\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": \"What is the recent deepseek news and then please tell me the recent research paper on agentic ai?\"})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ad0404",
   "metadata": {},
   "source": [
    "ReAct framework\n",
    "This last used workflow is the demonstration of the ReAct(Reasoning and Acting) framework of LLM models. Here the tool_calling_llm node will reason first and identify that if it needs to call a tool and how many contexts are there in the provided question or query. Then it will call the appropriate tool(s) based on the identified contexts and provide the final response. This helps in improving the LLM's efficiency and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b35cfc7",
   "metadata": {},
   "source": [
    "multiple tools like arxiv(for research), wikipedia(info),tavily(search engine)  etc are combined with the llm model qwen of chat groq . llm will reason the query , and calls the respective tools by itself and give a single response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976a5586",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
